"""
Logs Page - ë¡œê·¸ ë° ëª¨ë‹ˆí„°ë§

ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸ ë° ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

Author: AI Assistant
Created: 2025-11-22
"""

import streamlit as st
import os
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
import plotly.graph_objects as go
from collections import Counter
import json


LOG_DIR = Path(os.getenv('LOG_DIR', 'logs'))


def read_log_file(file_path: Path, lines: int = 100) -> list:
    """
    Read last N lines from log file

    Args:
        file_path: Path to log file
        lines: Number of lines to read

    Returns:
        List of log lines
    """
    if not file_path.exists():
        return []

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            all_lines = f.readlines()
            return all_lines[-lines:]
    except Exception as e:
        st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        return []


def parse_log_line(line: str) -> dict:
    """
    Parse log line

    Args:
        line: Log line

    Returns:
        Parsed log dict
    """
    try:
        # Try JSON format first
        return json.loads(line)
    except:
        # Fall back to text parsing
        parts = line.split(' - ', 3)
        if len(parts) >= 4:
            return {
                'timestamp': parts[0],
                'logger': parts[1],
                'level': parts[2],
                'message': parts[3].strip()
            }
        else:
            return {
                'timestamp': '',
                'logger': '',
                'level': 'UNKNOWN',
                'message': line.strip()
            }


def get_log_stats(lines: list) -> dict:
    """
    Get log statistics

    Args:
        lines: Log lines

    Returns:
        Statistics dict
    """
    levels = []
    loggers = []
    timestamps = []

    for line in lines:
        parsed = parse_log_line(line)
        levels.append(parsed.get('level', 'UNKNOWN'))
        loggers.append(parsed.get('logger', 'unknown'))

        ts = parsed.get('timestamp', '')
        if ts:
            try:
                timestamps.append(datetime.fromisoformat(ts.replace('Z', '+00:00')))
            except:
                pass

    level_counts = Counter(levels)
    logger_counts = Counter(loggers)

    return {
        'total_logs': len(lines),
        'level_counts': dict(level_counts),
        'logger_counts': dict(logger_counts),
        'timestamps': timestamps
    }


def show_log_viewer(log_file: Path, title: str, lines: int = 100):
    """
    Show log viewer

    Args:
        log_file: Path to log file
        title: Viewer title
        lines: Number of lines to show
    """
    st.markdown(f"### {title}")

    if not log_file.exists():
        st.info(f"ğŸ“ ë¡œê·¸ íŒŒì¼ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {log_file.name}")
        return

    # File info
    file_size = log_file.stat().st_size
    file_modified = datetime.fromtimestamp(log_file.stat().st_mtime)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("íŒŒì¼ í¬ê¸°", f"{file_size / 1024:.1f} KB")
    with col2:
        st.metric("ë§ˆì§€ë§‰ ìˆ˜ì •", file_modified.strftime('%H:%M:%S'))
    with col3:
        if st.button(f"ğŸ”„ ìƒˆë¡œê³ ì¹¨", key=f"refresh_{log_file.name}"):
            st.rerun()

    # Read logs
    log_lines = read_log_file(log_file, lines)

    if not log_lines:
        st.info("ë¡œê·¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return

    # Statistics
    stats = get_log_stats(log_lines)

    # Level distribution
    if stats['level_counts']:
        st.markdown("#### ë¡œê·¸ ë ˆë²¨ ë¶„í¬")

        level_colors = {
            'DEBUG': '#17a2b8',
            'INFO': '#28a745',
            'WARNING': '#ffc107',
            'ERROR': '#dc3545',
            'CRITICAL': '#6f42c1'
        }

        fig = go.Figure(data=[
            go.Bar(
                x=list(stats['level_counts'].keys()),
                y=list(stats['level_counts'].values()),
                marker_color=[level_colors.get(level, '#6c757d') for level in stats['level_counts'].keys()]
            )
        ])

        fig.update_layout(
            title=f"ì´ {stats['total_logs']}ê°œ ë¡œê·¸",
            xaxis_title="ë¡œê·¸ ë ˆë²¨",
            yaxis_title="ê°œìˆ˜",
            height=300
        )

        st.plotly_chart(fig, use_container_width=True)

    # Filter options
    st.markdown("#### í•„í„°")

    col1, col2 = st.columns(2)

    with col1:
        level_filter = st.multiselect(
            "ë¡œê·¸ ë ˆë²¨",
            options=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
            default=['ERROR', 'WARNING', 'INFO'],
            key=f"level_filter_{log_file.name}"
        )

    with col2:
        search_text = st.text_input(
            "ê²€ìƒ‰ì–´",
            key=f"search_{log_file.name}"
        )

    # Display logs
    st.markdown("#### ë¡œê·¸ ë‚´ìš©")

    filtered_logs = []
    for line in log_lines:
        parsed = parse_log_line(line)
        level = parsed.get('level', 'UNKNOWN')
        message = parsed.get('message', line)

        # Apply filters
        if level not in level_filter:
            continue

        if search_text and search_text.lower() not in message.lower():
            continue

        filtered_logs.append(line)

    if not filtered_logs:
        st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Show in text area (most recent first)
    log_text = ''.join(reversed(filtered_logs))

    st.text_area(
        f"{len(filtered_logs)}ê°œ ë¡œê·¸ (ìµœì‹ ìˆœ)",
        log_text,
        height=400,
        key=f"logs_{log_file.name}"
    )

    # Download button
    st.download_button(
        label="ğŸ“¥ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
        data=log_text,
        file_name=f"{log_file.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain",
        key=f"download_{log_file.name}"
    )


def show_system_status():
    """Show system status"""
    st.markdown("### ì‹œìŠ¤í…œ ìƒíƒœ")

    col1, col2, col3, col4 = st.columns(4)

    # Log directory status
    with col1:
        log_files = list(LOG_DIR.glob('*.log'))
        st.metric("ë¡œê·¸ íŒŒì¼", f"{len(log_files)}ê°œ")

    # Total log size
    with col2:
        total_size = sum(f.stat().st_size for f in log_files if f.exists())
        st.metric("ì´ ë¡œê·¸ í¬ê¸°", f"{total_size / (1024 * 1024):.1f} MB")

    # Latest log time
    with col3:
        if log_files:
            latest_time = max(f.stat().st_mtime for f in log_files if f.exists())
            latest_dt = datetime.fromtimestamp(latest_time)
            time_ago = (datetime.now() - latest_dt).total_seconds()

            if time_ago < 60:
                time_str = f"{int(time_ago)}ì´ˆ ì „"
            elif time_ago < 3600:
                time_str = f"{int(time_ago / 60)}ë¶„ ì „"
            else:
                time_str = f"{int(time_ago / 3600)}ì‹œê°„ ì „"

            st.metric("ë§ˆì§€ë§‰ ë¡œê·¸", time_str)
        else:
            st.metric("ë§ˆì§€ë§‰ ë¡œê·¸", "N/A")

    # Log directory path
    with col4:
        st.metric("ë¡œê·¸ ë””ë ‰í† ë¦¬", str(LOG_DIR))

    # Log files list
    if log_files:
        st.markdown("#### ë¡œê·¸ íŒŒì¼ ëª©ë¡")

        file_data = []
        for log_file in sorted(log_files, key=lambda x: x.stat().st_mtime, reverse=True):
            file_stat = log_file.stat()
            file_data.append({
                'íŒŒì¼ëª…': log_file.name,
                'í¬ê¸° (KB)': f"{file_stat.st_size / 1024:.1f}",
                'ë§ˆì§€ë§‰ ìˆ˜ì •': datetime.fromtimestamp(file_stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
            })

        df = pd.DataFrame(file_data)
        st.dataframe(df, use_container_width=True, hide_index=True)


def show_error_summary():
    """Show error summary from error.log"""
    st.markdown("### ì˜¤ë¥˜ ìš”ì•½")

    error_log = LOG_DIR / 'errors.log'

    if not error_log.exists():
        st.info("ğŸ“ ì˜¤ë¥˜ ë¡œê·¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    # Read recent errors
    error_lines = read_log_file(error_log, lines=50)

    if not error_lines:
        st.success("âœ… ìµœê·¼ ì˜¤ë¥˜ ì—†ìŒ")
        return

    # Parse errors
    errors = []
    for line in error_lines:
        parsed = parse_log_line(line)
        if parsed.get('level') in ['ERROR', 'CRITICAL']:
            errors.append(parsed)

    if not errors:
        st.success("âœ… ìµœê·¼ ì˜¤ë¥˜ ì—†ìŒ")
        return

    # Error count
    st.error(f"âš ï¸ ìµœê·¼ {len(errors)}ê°œ ì˜¤ë¥˜ ë°œê²¬")

    # Recent errors
    st.markdown("#### ìµœê·¼ ì˜¤ë¥˜ (ìµœëŒ€ 10ê°œ)")

    for error in errors[-10:]:
        with st.expander(
            f"ğŸ”´ {error.get('timestamp', 'N/A')} - {error.get('message', 'Unknown error')[:100]}",
            expanded=False
        ):
            st.code(error.get('message', 'Unknown error'), language='text')

            if 'exception' in error:
                st.markdown("**Stack Trace:**")
                st.code(error['exception'], language='python')


def show():
    """Show logs page"""
    st.title("ğŸ“‹ ë¡œê·¸ ë° ëª¨ë‹ˆí„°ë§")

    st.markdown("""
    ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³  ì˜¤ë¥˜ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
    """)

    # Auto-refresh option
    auto_refresh = st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", value=False)

    if auto_refresh:
        import time
        time.sleep(30)
        st.rerun()

    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ", "ğŸ“ ì „ì²´ ë¡œê·¸", "ğŸ”´ ì˜¤ë¥˜ ë¡œê·¸", "âš™ï¸ ì„¤ì •"])

    with tab1:
        show_system_status()
        st.markdown("---")
        show_error_summary()

    with tab2:
        log_file = LOG_DIR / 'stock_intelligence.log'

        # Number of lines to show
        lines = st.slider("í‘œì‹œí•  ë¡œê·¸ ê°œìˆ˜", 50, 500, 100, 50)

        show_log_viewer(log_file, "ì „ì²´ ì‹œìŠ¤í…œ ë¡œê·¸", lines)

    with tab3:
        error_log = LOG_DIR / 'errors.log'

        # Number of lines to show
        lines = st.slider("í‘œì‹œí•  ì˜¤ë¥˜ ê°œìˆ˜", 20, 200, 50, 10, key="error_lines")

        show_log_viewer(error_log, "ì˜¤ë¥˜ ë¡œê·¸", lines)

    with tab4:
        st.markdown("### ë¡œê·¸ ì„¤ì •")

        st.markdown("#### í˜„ì¬ ì„¤ì •")

        col1, col2 = st.columns(2)

        with col1:
            st.code(f"""
LOG_DIR: {LOG_DIR}
LOG_LEVEL: {os.getenv('LOG_LEVEL', 'INFO')}
            """.strip())

        with col2:
            st.markdown("""
            **ë¡œê·¸ ë ˆë²¨ ì„¤ëª…:**
            - DEBUG: ë””ë²„ê·¸ ì •ë³´
            - INFO: ì¼ë°˜ ì •ë³´
            - WARNING: ê²½ê³ 
            - ERROR: ì˜¤ë¥˜
            - CRITICAL: ì¹˜ëª…ì  ì˜¤ë¥˜
            """)

        st.markdown("---")

        st.markdown("#### ë¡œê·¸ ê´€ë¦¬")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ—‘ï¸ ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ (30ì¼ ì´ìƒ)", type="secondary"):
                cutoff_date = datetime.now() - timedelta(days=30)
                deleted_count = 0

                for log_file in LOG_DIR.glob('*.log.*'):  # Rotated logs
                    if log_file.stat().st_mtime < cutoff_date.timestamp():
                        log_file.unlink()
                        deleted_count += 1

                st.success(f"âœ… {deleted_count}ê°œ íŒŒì¼ ì‚­ì œë¨")

        with col2:
            if st.button("ğŸ“¦ ë¡œê·¸ ì••ì¶• ë° ë°±ì—…"):
                st.info("ì••ì¶• ê¸°ëŠ¥ì€ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")

        st.markdown("---")

        st.markdown("#### ë¡œê·¸ ë¡œí…Œì´ì…˜ ì •ë³´")

        st.markdown("""
        - **íŒŒì¼ í¬ê¸° ì œí•œ**: 10 MB
        - **ë°±ì—… ê°œìˆ˜**: 10ê°œ (ì „ì²´ ë¡œê·¸), 5ê°œ (ì˜¤ë¥˜ ë¡œê·¸)
        - **ì¸ì½”ë”©**: UTF-8
        - **ë¡œí…Œì´ì…˜ ë°©ì‹**: í¬ê¸° ê¸°ë°˜
        """)
